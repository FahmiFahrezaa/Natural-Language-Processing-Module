{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f5e31f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba01e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  \\\n",
      "0  One of the other reviewers has mentioned that ...  positive   \n",
      "1  A wonderful little production. <br /><br />The...  positive   \n",
      "2  I thought this was a wonderful way to spend ti...  positive   \n",
      "3  Basically there's a family where a little boy ...  negative   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
      "5  Probably my all-time favorite movie, a story o...  positive   \n",
      "6  I sure would like to see a resurrection of a u...  positive   \n",
      "7  This show was an amazing, fresh & innovative i...  negative   \n",
      "8  Encouraged by the positive comments about this...  negative   \n",
      "9  If you like original gut wrenching laughter yo...  positive   \n",
      "\n",
      "  predicted_sentiment true_sentiment  \n",
      "0            positive       positive  \n",
      "1            positive       positive  \n",
      "2            positive       positive  \n",
      "3            negative       negative  \n",
      "4            positive       positive  \n",
      "5            positive       positive  \n",
      "6            positive       positive  \n",
      "7            positive       negative  \n",
      "8            negative       negative  \n",
      "9            positive       positive  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "\n",
    "# Sentiment analysis using TextBlob\n",
    "def sentiment_textblob(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Apply sentiment analysis to review column\n",
    "df['predicted_sentiment'] = df['review'].apply(sentiment_textblob)\n",
    "\n",
    "# Compare with ground truth\n",
    "df['true_sentiment'] = df['sentiment'].apply(lambda x: 'positive' if x == 'positive' else 'negative')\n",
    "\n",
    "# Print first 10 rows of the dataframe\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af01a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\legion\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45388e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.1-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/10.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---------------------------------------- 0.1/10.8 MB 1.7 MB/s eta 0:00:07\n",
      "      --------------------------------------- 0.2/10.8 MB 1.4 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.2/10.8 MB 1.3 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.3/10.8 MB 1.2 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.4/10.8 MB 1.3 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.6/10.8 MB 1.7 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 0.8/10.8 MB 2.1 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.0/10.8 MB 2.4 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.0/10.8 MB 2.4 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.2/10.8 MB 2.3 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.5/10.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.5/10.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.5/10.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.5/10.8 MB 2.1 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.5/10.8 MB 2.1 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.5/10.8 MB 2.1 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 1.7/10.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 1.9/10.8 MB 2.1 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 2.2/10.8 MB 2.3 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.4/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 2.6/10.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 2.7/10.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 2.9/10.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 2.9/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 2.0 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 3.4/10.8 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 3.4/10.8 MB 2.0 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 3.5/10.8 MB 2.0 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 3.5/10.8 MB 2.0 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 3.5/10.8 MB 2.0 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 3.5/10.8 MB 1.9 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 4.2/10.8 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.3/10.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 4.7/10.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 4.8/10.8 MB 2.4 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 4.9/10.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.0/10.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.0/10.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.0/10.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.0/10.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.0/10.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.0/10.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.1/10.8 MB 2.0 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 5.2/10.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 6.2/10.8 MB 2.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 6.4/10.8 MB 2.4 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.5/10.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.7/10.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 6.9/10.8 MB 2.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 7.1/10.8 MB 2.5 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 7.4/10.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.7/10.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 8.1/10.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.3/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.4/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.4/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.4/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.4/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.4/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.1/10.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.4/10.8 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.4/10.8 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.4/10.8 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.4/10.8 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.4/10.8 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.4/10.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.8/10.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.8/10.8 MB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/341.8 kB ? eta -:--:--\n",
      "     -------- ---------------------------- 81.9/341.8 kB 919.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 341.8/341.8 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.0.1 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d925e37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\legion\\anaconda3\\lib\\site-packages (4.3.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77902979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\legion\\anaconda3\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\legion\\anaconda3\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74fc89f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.1/1.5 MB 1.2 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.2/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.4/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 0.6/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.7/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.8/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.1/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.2/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.4/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.5.5-cp38-cp38-win_amd64.whl (267 kB)\n",
      "     ---------------------------------------- 0.0/267.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/267.9 kB ? eta -:--:--\n",
      "     -------------------------------------  266.2/267.9 kB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 267.9/267.9 kB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\legion\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ---------------------------------------- 0.0/298.0 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 163.8/298.0 kB 5.0 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 163.8/298.0 kB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 298.0/298.0 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\legion\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\legion\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.2.0 nltk-3.8.1 regex-2023.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd42a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd13643",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d95f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                              TITLE   \n",
      "0   1        Reconstructing Subject-Specific Effect Maps  \\\n",
      "1   2                 Rotation Invariance Neural Network   \n",
      "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
      "3   4  A finite element approximation for the stochas...   \n",
      "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
      "\n",
      "                                            ABSTRACT  Computer Science   \n",
      "0    Predictive models allow subject-specific inf...                 1  \\\n",
      "1    Rotation invariance and translation invarian...                 1   \n",
      "2    We introduce and develop the notion of spher...                 0   \n",
      "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
      "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
      "\n",
      "   Physics  Mathematics  Statistics  Quantitative Biology  \n",
      "0        0            0           0                     0  \n",
      "1        0            0           0                     0  \n",
      "2        0            1           0                     0  \n",
      "3        0            1           0                     0  \n",
      "4        0            0           1                     0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"topicmodelling.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a5932a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.31086878819878755), (3, 0.2609846481106636), (4, 0.3564830756183952), (5, 0.3951638349062978), (6, 0.487800669676959), (7, 0.45098883564552966), (8, 0.4726759909462879), (9, 0.4901286290248069), (10, 0.5138595384882116), (11, 0.48563886638181536), (12, 0.5303147873623111), (13, 0.5363552514068115), (14, 0.5461062959823407), (15, 0.5386613053494289), (16, 0.535654178687943), (17, 0.47736533251683233), (18, 0.5333581024799596), (19, 0.37355235500160694)]\n",
      "Topic: 1 \n",
      "Words: ['poisson', 'kernels', 'spherical', 'functions', 'polyharmonic', 'polyharmonics', 'neural', 'specific', 'rotation', 'frequency']\n",
      "Topic: 2 \n",
      "Words: ['system', 'gilbert', 'finite', 'approximation', 'element', 'lifshitz', 'maxwell', 'landau', 'stochastic', 'fundamental']\n",
      "Topic: 3 \n",
      "Words: ['wavelet', 'plants', 'train', 'ftir', 'medicinal', 'tensor', 'decomposition', 'study', 'data', 'feature']\n",
      "Topic: 4 \n",
      "Words: ['effects', 'collisions', 'mars', 'material', 'sph', 'state', 'scale', 'role', 'calculations', 'numerical']\n",
      "Topic: 5 \n",
      "Words: ['rotation', 'predict', 'potential', 'presence', 'lightcurve', 'outbreak', 'fails', 'mathcal', 'natural', 'boosting']\n",
      "                                               TITLE  topic\n",
      "0        Reconstructing Subject-Specific Effect Maps      2\n",
      "1                 Rotation Invariance Neural Network      5\n",
      "2  Spherical polyharmonics and Poisson kernels fo...      1\n",
      "3  A finite element approximation for the stochas...      2\n",
      "4  Comparative study of Discrete Wavelet Transfor...      3\n",
      "5  On maximizing the fundamental frequency of the...      2\n",
      "6  On the rotation period and shape of the hyperb...      5\n",
      "7  Adverse effects of polymer coating on heat tra...      3\n",
      "8  SPH calculations of Mars-scale collisions: the...      4\n",
      "9  $\\mathcal{R}_{0}$ fails to predict the outbrea...      5\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and preprocess the abstracts\n",
    "stop_words = stopwords.words('english')\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(text):\n",
    "        if token not in stop_words:\n",
    "            result.append(token)\n",
    "    return result\n",
    "df['tokens'] = df['TITLE'].apply(preprocess)\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = gensim.corpora.Dictionary(df['tokens'])\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in df['tokens']]\n",
    "\n",
    "# Find the optimal number of topics using coherence score\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherence_model.get_coherence()\n",
    "        coherence_values.append((num_topics, coherence_score))\n",
    "    return coherence_values\n",
    "\n",
    "coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=df['tokens'], start=2, limit=20, step=1)\n",
    "print(coherence_values)\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5\n",
    "model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "# Print the topics and the top words for each topic\n",
    "for idx, topic in model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx+1, [word[0] for word in topic]))\n",
    "\n",
    "# Assign topics to documents\n",
    "df['topic'] = [sorted(model[corpus[i]], key=lambda x: x[1], reverse=True)[0][0]+1 for i in range(len(df))]\n",
    "print(df[['TITLE', 'topic']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86d9e2",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517c0c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurry will rose ser waymar royce was the youngest son of an ancient gnarled ironwood and dismounted. Will said fear had made him insolent perhaps my lord would care to take orders from a. Long enough to kill eight grown men men clad in fur and leather let me remind you. And twisted like a tree struck by lightning will knelt looked around warily and snatched it up. Not with this horse will said fear had made him insolent perhaps my lord would care to. Too late the pale sword came shivering through the ringmail beneath his arm the young lord said. Of yet it was on the snow and the mud and looked down no fire gared s. A halfmoon rose will was grateful for the lordling the scars around his ear holes flushed red. If there are enemies in this wood a fire will turned away lead on he said we. From the dark of the firepit the snowcovered leanto the great sentinel was right there at the. \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Load the dataset\n",
    "f = open('game_of_thrones.txt')\n",
    "raw_text = f.read()\n",
    "f.close()\n",
    "\n",
    "# Preprocessing\n",
    "raw_text = raw_text.lower() # convert to lowercase\n",
    "sentences = nltk.sent_tokenize(raw_text) # tokenize into sentences\n",
    "word_tokens = nltk.word_tokenize(raw_text) # tokenize into words\n",
    "# Remove punctuations\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in word_tokens]\n",
    "# Remove non-alphabetic words\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "# Build the Markov model\n",
    "def build_model(words, order=2):\n",
    "    model = {}\n",
    "    for i in range(len(words)-order):\n",
    "        gram = ' '.join(words[i:i+order])\n",
    "        next_word = words[i+order]\n",
    "        if gram in model:\n",
    "            model[gram].append(next_word)\n",
    "        else:\n",
    "            model[gram] = [next_word]\n",
    "    return model\n",
    "\n",
    "# Generate a sentence\n",
    "def generate_sentence(model, order=2, length=15):\n",
    "    # Choose a random starting point\n",
    "    n = random.randint(0, len(words)-order)\n",
    "    current_gram = ' '.join(words[n:n+order])\n",
    "    result = current_gram\n",
    "    for i in range(length):\n",
    "        if current_gram not in model:\n",
    "            break\n",
    "        possible_words = model[current_gram]\n",
    "        next_word = possible_words[random.randint(0, len(possible_words)-1)]\n",
    "        result += ' ' + next_word\n",
    "        # Update current_gram\n",
    "        current_gram = ' '.join(result.split()[-order:])\n",
    "    return result\n",
    "\n",
    "# Generate a paragraph of 10 sentences\n",
    "paragraph = ''\n",
    "for i in range(10):\n",
    "    sentence = generate_sentence(build_model(words), length=15)\n",
    "    paragraph += sentence.capitalize() + '. '\n",
    "print(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f8b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
